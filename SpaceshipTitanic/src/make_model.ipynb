{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deecbe77",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2780a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Input, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import KFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4c9d3",
   "metadata": {},
   "source": [
    "# Define base directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ecfd91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ef3c4",
   "metadata": {},
   "source": [
    "# File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6072d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data List\n",
      "['description', 'sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "print(\"Data List\")\n",
    "print(os.listdir(\"data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e549b45",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651134f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:(8693, 14)\n",
      "test shape:(4277, 13)\n",
      "sample_submission shape:(4277, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "print(f\"train shape:{train.shape}\")\n",
    "print(f\"test shape:{test.shape}\")\n",
    "print(f\"sample_submission shape:{sample_submission.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f369dd4b",
   "metadata": {},
   "source": [
    "# Split with features and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7a95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ans = train[\"Transported\"] * 1.0\n",
    "train = train.drop(\"Transported\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24366cf1",
   "metadata": {},
   "source": [
    "# => Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17197520",
   "metadata": {},
   "source": [
    "## Define data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327d51bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Changed=================\n",
      "column:<PassengerId>  object    -->    object\n",
      "column:<HomePlanet>  object    -->    category\n",
      "column:<CryoSleep>  object    -->    boolean\n",
      "column:<Cabin>  object    -->    category\n",
      "column:<Destination>  object    -->    category\n",
      "column:<Age>  float64    -->    float64\n",
      "column:<VIP>  object    -->    boolean\n",
      "column:<RoomService>  float64    -->    float64\n",
      "column:<FoodCourt>  float64    -->    float64\n",
      "column:<ShoppingMall>  float64    -->    float64\n",
      "column:<Spa>  float64    -->    float64\n",
      "column:<VRDeck>  float64    -->    float64\n",
      "column:<Name>  object    -->    category\n"
     ]
    }
   ],
   "source": [
    "old_dtypes = train.dtypes\n",
    "\n",
    "dtype_dict = {\n",
    "    \"PassengerId\": \"object\",\n",
    "    \"HomePlanet\": \"category\",\n",
    "    \"CryoSleep\": \"boolean\",\n",
    "    \"Cabin\": \"category\",\n",
    "    \"Destination\": \"category\",\n",
    "    \"Age\":\"float\",\n",
    "    \"VIP\": \"boolean\",\n",
    "    \"RoomService\": \"float\",\n",
    "    \"FoodCourt\": \"float\",\n",
    "    \"ShoppingMall\": \"float\",\n",
    "    \"Spa\": \"float\",\n",
    "    \"VRDeck\": \"float\",\n",
    "    \"Name\": \"category\",    \n",
    "}\n",
    "train = train.astype(dtype_dict)\n",
    "new_dtypes = train.dtypes\n",
    "print(\"===============Changed=================\")\n",
    "for _index, _old, _new in zip(old_dtypes.index, old_dtypes, new_dtypes):\n",
    "    print(f\"column:<{_index}>  {_old}    -->    {_new}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1011c565",
   "metadata": {},
   "source": [
    "## Drop unused features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b47f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop([\"Name\", \"PassengerId\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd21c56",
   "metadata": {},
   "source": [
    "## Split merged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8782da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = train[\"Cabin\"].str.split(\"\\/\", expand=True)\n",
    "sub_df.columns = [\n",
    "    \"Cabin_A\",\n",
    "    \"Cabin_B\",\n",
    "    \"Cabin_C\"\n",
    "]\n",
    "sub_df = sub_df.astype({\n",
    "    \"Cabin_A\": \"category\",\n",
    "    \"Cabin_B\": \"float\",\n",
    "    \"Cabin_C\": \"category\"\n",
    "})\n",
    "train = pd.concat([train, sub_df], axis=1)\n",
    "train = train.drop(\"Cabin\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff810f",
   "metadata": {},
   "source": [
    "## Null padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4178ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age',\n",
       " 'Cabin_B',\n",
       " 'CryoSleep',\n",
       " 'FoodCourt',\n",
       " 'RoomService',\n",
       " 'ShoppingMall',\n",
       " 'Spa',\n",
       " 'VIP',\n",
       " 'VRDeck'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_features = set(train.isnull().sum()[train.isnull().sum() > 0].index)\n",
    "target_features &= set(train.dtypes[(train.dtypes == \"float\") | (train.dtypes == \"boolean\")].index)\n",
    "target_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e2c30b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in target_features:\n",
    "    null_colmun_name = column + \"_NULL\"\n",
    "    train[null_colmun_name] = train[column].isna() * 1.0\n",
    "    train[column] = train[column].fillna(0.0)\n",
    "    # for boolean\n",
    "    train[column] = train[column] * 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def7b24",
   "metadata": {},
   "source": [
    "## One-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43748e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only categorical features\n",
    "encoders = {}\n",
    "for column in train.columns:\n",
    "    if train[column].dtype != \"category\":\n",
    "        continue\n",
    "    arr_data = np.array(train[column].values).reshape(-1, 1)\n",
    "    encoder = OneHotEncoder().fit(arr_data)\n",
    "    sub_df = pd.DataFrame(\n",
    "        encoder.transform(arr_data).toarray(),\n",
    "        columns = [f\"{column}_{_category}\" for _category in encoder.categories_[0]]\n",
    "    )\n",
    "    train = train.drop(column, axis=1)\n",
    "    train = pd.concat([train, sub_df], axis=1)\n",
    "    encoders[column] = encoder\n",
    "with open(\"./model/encoders.pkl\", \"wb\") as f:\n",
    "    pickle.dump(encoders, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a581633",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be45c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(srs):\n",
    "    return (srs - srs.min()) / (srs.max() - srs.min())\n",
    "\n",
    "for _column in train.columns:\n",
    "    train[_column] = norm(train[_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d608120",
   "metadata": {},
   "source": [
    "## Function process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f66cad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomModel(keras.Model):\n",
    "#     def __init__(self, hidden_units):\n",
    "#         super(CustomModel, self).__init__()\n",
    "#         self.dense_layers = [keras.layers.Dense(u) for u in hidden_units]\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x = inputs\n",
    "#         for layer in self.dense_layers:\n",
    "#             x = layer(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07017f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def F1ScoreCustom(y_true, y_pred):\n",
    "    y_pred = tf.cast((y_pred > 0.5), tf.float64) * 1.0\n",
    "    return tf.constant(f1_score(y_true.numpy(), y_pred.numpy()), dtype=tf.float64)\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='F1Score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.true_negatives = self.add_weight(name='tn', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.bool)\n",
    "        y_pred = tf.cast(y_pred > 0.5, tf.bool)\n",
    "#         print(tf.reduce_sum(tf.cast(y_pred, self.dtype)))\n",
    "        tp = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
    "        tp = tf.reduce_sum(tf.cast(tp, self.dtype))\n",
    "        \n",
    "        tn = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, False))\n",
    "        tn = tf.reduce_sum(tf.cast(tn, self.dtype))\n",
    "\n",
    "        fp = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, True))\n",
    "        fp = tf.reduce_sum(tf.cast(fp, self.dtype))\n",
    "        \n",
    "        fn = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, False))\n",
    "        fn = tf.reduce_sum(tf.cast(fn, self.dtype))\n",
    "        \n",
    "#         if sample_weight is not None:\n",
    "#             sample_weight = tf.cast(sample_weight, self.dtype)\n",
    "#             sample_weight = tf.broadcast_to(sample_weight, values.shape)\n",
    "#             values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.cast(tp, self.dtype))\n",
    "        self.true_negatives.assign_add(tf.cast(tn, self.dtype))\n",
    "        self.false_positives.assign_add(tf.cast(fp, self.dtype))\n",
    "        self.false_negatives.assign_add(tf.cast(fn, self.dtype))\n",
    "    \n",
    "    def result(self):\n",
    "        self.recall = self.true_positives / (self.true_positives + self.true_negatives)\n",
    "        self.precision = self.true_positives / (self.true_positives + self.false_positives)\n",
    "        return tf.cast(2 * (self.recall * self.precision) / (self.recall + self.precision), self.dtype)\n",
    "    \n",
    "class F1Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(F1Loss, self).__init__(**kwargs)\n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_boolean = K.cast(y_pred > 0.5, K.floatx())\n",
    "        tp = K.sum(K.cast(K.equal(y_true, 1) & K.equal(y_pred_boolean, 1), K.floatx()))\n",
    "        tn = K.sum(K.cast(K.equal(y_true, 1) & K.equal(y_pred_boolean, 0), K.floatx()))\n",
    "        fp = K.sum(K.cast(K.equal(y_true, 0) & K.equal(y_pred_boolean, 1), K.floatx()))\n",
    "        fn = K.sum(K.cast(K.equal(y_true, 0) & K.equal(y_pred_boolean, 0), K.floatx()))\n",
    "#         tp = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
    "#         tp = tf.reduce_sum(tf.cast(tp, tf.float64))\n",
    "        \n",
    "#         tn = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, False))\n",
    "#         tn = tf.reduce_sum(tf.cast(tn, tf.float64))\n",
    "\n",
    "#         fp = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, True))\n",
    "#         fp = tf.reduce_sum(tf.cast(fp, tf.float64))\n",
    "        \n",
    "#         fn = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, False))\n",
    "#         fn = tf.reduce_sum(tf.cast(fn, tf.float64))\n",
    "        \n",
    "        recall = tp / (tp + tn)\n",
    "        precision = tp / (tp + fp)\n",
    "        tensor = K.cast_to_floatx(2 * (recall * precision) / (recall + precision))\n",
    "#         return tensor\n",
    "        tensor2 = K.mean(K.square(K.cast_to_floatx(y_true) - K.cast_to_floatx(y_pred)))\n",
    "        print(tensor, tensor2)\n",
    "        return tensor2\n",
    "\n",
    "class MSELoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MSELoss, self).__init__(**kwargs)\n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        return K.mean(K.square(K.cast_to_floatx(y_true) - K.cast_to_floatx(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80152dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(\n",
    "    model_name, \n",
    "    train_feature,\n",
    "    train_target, \n",
    "    val_valfeature, \n",
    "    val_target\n",
    "):\n",
    "    # Stack layers\n",
    "    inputs = Input(shape=(train_feature.shape[1]))\n",
    "    layer = Dense(256, activation=\"relu\")(inputs)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(256, activation=\"relu\")(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(128, activation=\"relu\")(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(1, activation=\"sigmoid\")(layer)\n",
    "    dl_model = Model(inputs=inputs, outputs=layer)\n",
    "    \n",
    "    # Compile\n",
    "    dl_model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=F1Loss(),\n",
    "            metrics=[\n",
    "                F1Score(), \n",
    "#                 tf.keras.metrics.BinaryAccuracy(threshold=0.5), \n",
    "#                 tf.keras.metrics.CategoricalAccuracy()\n",
    "            ],\n",
    "            loss_weights=None,\n",
    "            sample_weight_mode=None,\n",
    "            weighted_metrics=None,\n",
    "            target_tensors=None,\n",
    "            run_eagerly=True\n",
    "    )\n",
    "    \n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=3\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                filepath=f\"./model/model_{model_name}.h5\",\n",
    "                vervose=1,\n",
    "                save_best_only=True,\n",
    "                save_weight_only=True\n",
    "            )\n",
    "        ]\n",
    "    # Training\n",
    "    dl_model.fit(\n",
    "        train_feature.astype(\"float\").values,\n",
    "        train_target.astype(\"float\").values,\n",
    "        batch_size=256,\n",
    "        epochs=30,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(val_valfeature.astype(\"float64\").values, val_target.astype(\"float64\").values),\n",
    "        shuffle=True,\n",
    "        class_weight=None,\n",
    "        sample_weight=None,\n",
    "        initial_epoch=0,\n",
    "        steps_per_epoch=None,\n",
    "        validation_steps=None\n",
    "    )\n",
    "    dl_model.load_weights(f\"./model/model_{model_name}.h5\")\n",
    "    acc = dl_model.evaluate(val_valfeature.astype(\"float64\").values, val_target.astype(\"float64\").values)\n",
    "    \n",
    "    return acc[1], f1_score(dl_model.predict(val_valfeature.astype(\"float64\").values) > 0.5, val_target.astype(\"float64\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "200d4860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature shape: 38\n",
      "Epoch 1/30\n",
      "tf.Tensor(0.55172414, shape=(), dtype=float32) tf.Tensor(0.29800245, shape=(), dtype=float32)\n",
      " 1/31 [..............................] - ETA: 3s - loss: 0.2980 - F1Score: 0.5517tf.Tensor(0.5525292, shape=(), dtype=float32) tf.Tensor(0.31337154, shape=(), dtype=float32)\n",
      " 2/31 [>.............................] - ETA: 2s - loss: 0.3057 - F1Score: 0.5521tf.Tensor(0.6268657, shape=(), dtype=float32) tf.Tensor(0.26824185, shape=(), dtype=float32)\n",
      " 3/31 [=>............................] - ETA: 2s - loss: 0.2932 - F1Score: 0.5776tf.Tensor(0.64197534, shape=(), dtype=float32) tf.Tensor(0.2381374, shape=(), dtype=float32)\n",
      " 4/31 [==>...........................] - ETA: 1s - loss: 0.2794 - F1Score: 0.5928tf.Tensor(0.65637064, shape=(), dtype=float32) tf.Tensor(0.22405893, shape=(), dtype=float32)\n",
      " 5/31 [===>..........................] - ETA: 1s - loss: 0.2684 - F1Score: 0.6056tf.Tensor(0.7035573, shape=(), dtype=float32) tf.Tensor(0.22852345, shape=(), dtype=float32)\n",
      " 6/31 [====>.........................] - ETA: 1s - loss: 0.2617 - F1Score: 0.6217tf.Tensor(0.68679243, shape=(), dtype=float32) tf.Tensor(0.2322894, shape=(), dtype=float32)\n",
      " 7/31 [=====>........................] - ETA: 1s - loss: 0.2575 - F1Score: 0.6312tf.Tensor(0.70781887, shape=(), dtype=float32) tf.Tensor(0.21273221, shape=(), dtype=float32)\n",
      " 8/31 [======>.......................] - ETA: 1s - loss: 0.2519 - F1Score: 0.6403tf.Tensor(0.68799996, shape=(), dtype=float32) tf.Tensor(0.24624991, shape=(), dtype=float32)\n",
      " 9/31 [=======>......................] - ETA: 1s - loss: 0.2513 - F1Score: 0.6455tf.Tensor(0.6692914, shape=(), dtype=float32) tf.Tensor(0.24232057, shape=(), dtype=float32)\n",
      "10/31 [========>.....................] - ETA: 1s - loss: 0.2504 - F1Score: 0.6479tf.Tensor(0.67782426, shape=(), dtype=float32) tf.Tensor(0.22282742, shape=(), dtype=float32)\n",
      "11/31 [=========>....................] - ETA: 1s - loss: 0.2479 - F1Score: 0.6504tf.Tensor(0.6666667, shape=(), dtype=float32) tf.Tensor(0.22884302, shape=(), dtype=float32)\n",
      "12/31 [==========>...................] - ETA: 1s - loss: 0.2463 - F1Score: 0.6517tf.Tensor(0.6413502, shape=(), dtype=float32) tf.Tensor(0.24370123, shape=(), dtype=float32)\n",
      "13/31 [===========>..................] - ETA: 1s - loss: 0.2461 - F1Score: 0.6510tf.Tensor(0.7079646, shape=(), dtype=float32) tf.Tensor(0.19950177, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64253396, shape=(), dtype=float32) tf.Tensor(0.23186523, shape=(), dtype=float32)\n",
      "15/31 [=============>................] - ETA: 1s - loss: 0.2420 - F1Score: 0.6539tf.Tensor(0.7016129, shape=(), dtype=float32) tf.Tensor(0.2073476, shape=(), dtype=float32)\n",
      "16/31 [==============>...............] - ETA: 0s - loss: 0.2399 - F1Score: 0.6569tf.Tensor(0.6612903, shape=(), dtype=float32) tf.Tensor(0.24393106, shape=(), dtype=float32)\n",
      "17/31 [===============>..............] - ETA: 0s - loss: 0.2401 - F1Score: 0.6572tf.Tensor(0.72796935, shape=(), dtype=float32) tf.Tensor(0.2166197, shape=(), dtype=float32)\n",
      "18/31 [================>.............] - ETA: 0s - loss: 0.2388 - F1Score: 0.6613tf.Tensor(0.7078189, shape=(), dtype=float32) tf.Tensor(0.21049024, shape=(), dtype=float32)\n",
      "19/31 [=================>............] - ETA: 0s - loss: 0.2373 - F1Score: 0.6637tf.Tensor(0.70638293, shape=(), dtype=float32) tf.Tensor(0.2203986, shape=(), dtype=float32)\n",
      "20/31 [==================>...........] - ETA: 0s - loss: 0.2365 - F1Score: 0.6657tf.Tensor(0.6695652, shape=(), dtype=float32) tf.Tensor(0.206516, shape=(), dtype=float32)\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 0.2350 - F1Score: 0.6659tf.Tensor(0.74603176, shape=(), dtype=float32) tf.Tensor(0.2010728, shape=(), dtype=float32)\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.2335 - F1Score: 0.6696tf.Tensor(0.6754386, shape=(), dtype=float32) tf.Tensor(0.22154833, shape=(), dtype=float32)\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.2330 - F1Score: 0.6698tf.Tensor(0.69827586, shape=(), dtype=float32) tf.Tensor(0.2122539, shape=(), dtype=float32)\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.2321 - F1Score: 0.6710tf.Tensor(0.63793105, shape=(), dtype=float32) tf.Tensor(0.23666133, shape=(), dtype=float32)\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.2323 - F1Score: 0.6697tf.Tensor(0.71129704, shape=(), dtype=float32) tf.Tensor(0.19389512, shape=(), dtype=float32)\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.2308 - F1Score: 0.6713tf.Tensor(0.6329114, shape=(), dtype=float32) tf.Tensor(0.22658291, shape=(), dtype=float32)\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.2307 - F1Score: 0.6699tf.Tensor(0.6866953, shape=(), dtype=float32) tf.Tensor(0.2157372, shape=(), dtype=float32)\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.2301 - F1Score: 0.6705tf.Tensor(0.6806723, shape=(), dtype=float32) tf.Tensor(0.22368965, shape=(), dtype=float32)\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.2299 - F1Score: 0.6708tf.Tensor(0.7068966, shape=(), dtype=float32) tf.Tensor(0.1917342, shape=(), dtype=float32)\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.2286 - F1Score: 0.6720tf.Tensor(0.7377049, shape=(), dtype=float32) tf.Tensor(0.17438334, shape=(), dtype=float32)\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2276 - F1Score: 0.6730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, random_state=91, shuffle=True)\n",
    "results = {}\n",
    "for index, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    train_feature = train.loc[train_index].reset_index(drop=True)\n",
    "    train_target = train_ans.loc[train_index].reset_index(drop=True)\n",
    "    \n",
    "    val_feature = train.loc[test_index].reset_index(drop=True)\n",
    "    val_target = train_ans.loc[test_index].reset_index(drop=True)\n",
    "    \n",
    "    print(\"feature shape:\", train_feature.shape[1])\n",
    "    acc, f1 = process(\n",
    "        index,\n",
    "        train_feature,\n",
    "        train_target, \n",
    "        val_feature, \n",
    "        val_target\n",
    "    )\n",
    "    results[index] = (acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71791bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "# import lazypredict\n",
    "# from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LazyClassifier(verbose=0,\n",
    "#                      ignore_warnings=True,\n",
    "#                      custom_metric=None,\n",
    "#                      predictions=False,\n",
    "#                      random_state=12,\n",
    "#                      classifiers='all')\n",
    "\n",
    "# models, predictions = clf.fit(X_train , X_test , y_train , y_test)\n",
    "# clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
